{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A19nG8RRKgl"
      },
      "source": [
        "#Implementing a simple POS-tagger\n",
        "\n",
        "Part-of-speech tagging is a **classification** task where for each token a particular descriptor is assigned, called **tag**. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3vhPGhKQF3z"
      },
      "source": [
        "![image.png](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAwgAAADgCAYAAACn+kFlAAAgAElEQVR4Ae2d95MUR5qG2di7i9u7iL29i409gzcDMxoG7xEw+MH7wSOEF0Y4gRjM4L1nQBjB4L13QkhYoZUBGYRAAiGBQAKJldk7/oG8eGv01WTXVDPtqqe78/2hI6tNtcnvyS/zqazKLvb06VPFG+uADJABMkAGyAAZIANkgAyQATBQjCAQBDJABsgAGSADZIAMkAEyQAaEAQoCZ1A4g0QGyAAZIANkgAyQATJABmwGKAiEwYZBrJEljyCQATJABsgAGSADZMBcBigIFAQKAhkgA2SADJABMkAGyAAZsBmgIBAGGwYeKTD3SAFjz9iTATJABsgAGSADwgAFgYJAQSADZIAMkAEyQAbIABkgAzYDFATCYMMg1siSRxDIABkgA2SADJABMmAuAxQECgIFgQyQATJABsgAGSADZIAM2AxQEAiDDQOPFJh7pICxZ+zJABkgA2SADJABYYCCQEGgIJABMkAGyAAZIANkgAyQAZsBCgJhsGEQa2TJIwhkgAyQATJABsgAGTCXAQoCBYGCQAbIABkgA2SADJABMkAGbAYoCITBhoFHCsw9UsDYM/ZkgAyQATJABsiAMEBBoCBQEMgAGSADZIAMkAEyQAbIgM0ABYEw2DCINbLkEQQyQAbIABkgA2SADJjLAAWBgkBBIANkgAyQATJABsgAGSADNgMUBMJgw8AjBeYeKWDsGXsyQAbIABmIJQbu37+vNmxYq4YM6a/S0xuo5EpJqnjx4kbd6tSprrp2ba/mzs1Wly5fjOp4rUgF4a9/fVft3btbrVixSM2fn23MbeXKJWrfvt3q/fffi2qwY6Xhf/nll+rEiWPqtfVrjIk5+F60aLbaunWzeuvts+pvf/ubkbHXGbx37546efK4Wr8hR81fYE77X7holtqSu0mdPXtG/fDDD8ZzACa+/vpriwUTc0Ju7iYrJ/z4449Gs/Do0SN1+PABNWfOdDVs2ADVpUsb1bFTKyNunTq3VoMH91XZ2VPUnr071f3794xmAf1jdvY0VbZsGaNkIBD56dKlrbp27VpU+Ii6INy4ccOywQrlyzHwxYurpArl1PDhA9XNmzejEnB9gBbN7SdPnqgFC2apqlVTGfffjoC0a9dcHTt+OKHj7mTsp59+UstXLFL169ckB79xkJGRrvYf2GMUB+ACg4AlS+aTBe2IaJu2zaxBsrPdJPJ9yOHLL49QJUuWZE7QWBgwIFN9+umnxuWF7777TrVq1dRmoVnzemroiK5q1rxhaufeWerUm8uNuR0+vlCteW2impQ1QPXqk2HXCcTp1KmTnrMRVUGYN2+2/QPFlNKb1lEvje5hBR8AmHAbPbanat6ifoG6WLx4vucBL4qO5uLFi6py5ed8fm/dulVV/xfaGxFvnekePVuqlBTfaVJMH+LoWVHEJpqf+cEHH6jq1av4cFCjRqrq06+tcRwg2VetmuJTFx07Zih0jtGMSVF91pUrV1SVKpV9fj9zQv6pEzhKaAIL58+fVxWTKtgcVKmSolpnPK9eHNzJuJwwckym6tgpXVWvnn8QrXSpUmrX7u1G5ATkIsyiNWpU2+Zh7sKX1P3Hh9XjX07w9ssJtW7jZFWqVL5IHz16xFM2oiYIo0YNsYPeqnVDte/QPPXFN3uNDvrte/vU7v2zfQYKY8cN9zTg0R4QHD580I47pHBlzjh17foWo+OOZHf2wmrVtXsLu24aNqxtnWYR7fhE6/NOv3FKVShf1v69WTMGqXfeX288B1c+2GAdIJEDJnXrVle3b99OqBzgZOzkqROqnHbqAHNC3uDHmRPq1auh7ty5k7AsHD122M4H4H/L9mnG5wMZCOesf0VVqJB/lkVOzvKE5UDyw//93/+pnj072Uz89dom8uAiRt/+cERhVgVtpny5sur69euesREVQZg581U76DiaKo2AZV7HcPfBAdWmbSO7jubPn+lZwKUxRqN8990rCkdAAHKt2mnq/Y/Y4J3MT8sebMe9RYtG6ueff06I2Ot8ffzxx/aAELMn5y7nMAc4Ev+yVWNtDho2rGMdSdPrMFG2MYtUtkxp5gRH/PW8oOeE9PT6CXm9kp4TGjeprW7d3c2c4GDiwQ9HVLv2ja22UqJECeu6vUTJA26/Axcjy4ESnEqktwluF5xBkbpq1qyxgly51Wm4j3kuCMeOH7WDjqPlDHTBQEudTM4aYNfVmTff8CTg4QIT6P4PHz5UqanJ1u/BaSTyG1m6x18a+5gxI+I67k4+cJ557drVyIGj8/fXDoSDwYP7JxQH4AIXZFevnkYWgmRh+IhBCcdC3bp51yClplZi31AIDzglGXmhYsUKCqv6OHNsItx//PixSk6uaP1OnGblLz/y8fzxw8GjC6z6Ahtbt77uCReeCgKOhspFqQx6fmCfBTnqCQGvWbOa+vXXXz0JejQSysSJo214r/KUokIT3pGTi+z6unLlctzG3cnWzJlT7N9FDgrPAToH58+/nTAcgIusrAlkoZDBoN43JCoLS5fOtznABaf6b+a2e46QaxZHjx6SUDlB+ovde3aRiSByg7QTXL+L8WLHjq094cJTQXhtfY715ZOSyvG0ggCDj3OSUV+WFW7b7EnQpVF6Vd67943d2FesGccOIMDYywxSZmaHuIy7kyccFQLHuJED945fEr1eCgdY5cpZp/F6HxfckoXAGRAehIVOnbwZABQFTzKzvHDpKPYNAfYNp99aYbUfrPT06NH3CZMXhL9hw160fh+uTxX2WRaeL3J3ztC4iPxCJ54KQmZmZ+vLjxjZnUEPMBGgUQwZ3tWqt/79M+MyEeRu3Wx9//oNqjPuQcT9/Dt552DiHG0sCyvJM17LAwf3WRxgtR4m+8KTvdSRcIDzjhNldatdu3eQhSBygZOFvIFh5AcA0c4t+O8fEcVPPt/GvBAEE7iOD3WH/1CKdty8/rzGjfNWdZwwqS+ZCIKJjz/fZrenS5cuRZwLTwXhuecqWV8e67hKwmNZ+EBhyYoxVr3hfF2vG6YX7z9xYt73HzSkM+MeRGP/6sEBu7Fffifyjd2LWD/rPbOzs6zf07ZdY3IQIgdvnDkdlznAycWUKRPJQhAMSD+p54S3z70V9yxs3rzJ4oAHjwofBwgDUsrpxzOyX417Dpz5IS0tb8nn3B3T2VcEmSdq185bOvzI0cj/p5JngoCLE+VIAVctCS4ZnDm3yqo7HEH8+9//HnfJoFevvBmQpStfZmMPsrHLGth79+2Ku7g7k/6QIf0tjvEnN9LJsQwsFwgHm7dsjHsOwMWAAXkXWpKFwOKvtxNhYfuO3LhnYeHCOVZO4MGj4DmQ881HjBgY9xw4+4rkSnn/hcFrUoLnQsRx956dEefCM0G4efNzWxD0ZMftwAAQubpzJ/7WRMdynfj+bOyBxVpvE9LYV61aHPHG7kzKXt/v2KmVxQGXNg6dg/kLsuOeA3DWpk3eP6OShdBZWLp0XtyzMGXKeOaEIA8aSf+AtoN+tWfPjnHPgbPvoSAEnxeECxkzxJUgXP/sUwtmAC0/hGXgEIgg3Lr1edwlg/T0BlbsKQiBx1vahjT2ZcvifzCAi2zBMQeFoXMwa/bUuGv/zs4f91u1akIWQhwYSk5IBFmc/Oo4chAiByIIPRJkEQs9T1AQgu8jnGMGCkKIDUsqMp5KCkLoDSae4uz8rjIYoCCYGX/hQTigIJjNAXgQFigIZrNAQTA7/tI3OEvJDxQECkJcHE3kDELoiUwaOwUh9Dp0JtB4vC8cUBDM5gDsCgsUBLNZoCCYHX9//ZjkBwoCBYGCkOAMSGOnIJjdGQgHFASzOaAgMP4yMKQgkAVhQS+lr6AgJPjgUA86TzEyMxlIY6cgmBl/yQHCAQXBbA7Ag7DAGQSzWaAgmB1/6RucpeQHCgIFgTMICc6ANHYKgtmdgXBAQTCbAwoC4y8DQgoCWRAW9FL6CgqCNji8+dVuhX+Rc7t9/fBggZWTHv183PW1n9zcrr76dr969HNB+G7f2+e6Dz7z9v19BT5DD1q425xBKBgPifWN27vUwx+Putb/9S922DFD/BCHz77caT8m7yGlvMYZr2++P+i6z6e3dqhvHx9x/Wzne4RyXxo7BaFg/AOpz68fHvATt+3q3veHXON26+4e133AiMXaE3fWAvk+ob5GOKAghMYB6v3uA3cWENc7z8jfkhsKK7/4Zq8rT6HG3N9+wgJnEAJnATl/175Z6vWtU63byTeXq4cu7fjClbX2a65e32LHE7HfumuG/dxbF1er7/52zH5eYnXm7ZXWazZvm2blEHnci5KCEHj8vaj/WH1PyQ8UBE0QevTMW2NdBtJ6OXpsT3Xq7HL14Mf8gdy9R4es5dX012G7XLkyavCwLmrHnpnKOVic+Go/132wX59+bdWBI/M9EwX5nlzmND8pSJ3Ur19NvX1pTYFkjQZct25VK2YlS5ZUU7MHWa9p1LiW3zhm9mqldu+fra5pnQPeB//oKJ+nl1iObe7CEdY+XiQMaewUhPy4B1PP+Nd2PV6yXTGpvJo89QW1a99shYMF+nv2HdDOdR/sC55WrZ2gPvhks/r+J9/99PeI9LZwQEEIjQPEY9mqsX7j2m9Ae6sNH39jqQ8L2E+YKazEH1dFOu5u7ycsUBACZ+HwiYWqRo1UO5Z161VVR08tLhCvqTMG2a+BTEj9Qy4qVSxvP9ckvY5y+8NX/PEfOClVqqQlJLK/FyUFIfD4e1H/sfqekh8oCAEKAhosksOeA3PsBu9PEPROYMSoHj6DgGcJAvYrX66sWrx8jP0ZkQRIvhcFIT8pPPdcRTth7z88r0C9v/fRJlWt2nPWa+rVr6ZwdAcxeZYgSD337N1aYfZBYuhPEOT1KJevHme/XvYLt5TGTkHIj3swdepPEJ4Vt2cJguzXuWsz9cXX0TlijN8rHFAQQuMAdfgsQZC4pqUl+/QT2E+eK6ykIDwN+pTXaP0PglMQEMv+L7S3ZpP1fBKoIGB/jA9wtoG+PwUheAb0/z+Qbf4PQuh5TvoKCoIfQWjZqoE6eHSB2r47W6Wm5g8im7eorzCFiAatCwIGjxu3ZFkzAM2a1/PpEPRZB10QMPDEZ0A60tPr2Pugg9m6c4ZP0tATSKjb0jlREPIbzs69s+x6nzl3WIFTfSa+2l+VLl3Keg0ajdS9CELJkiVU3/7trDgilsnJeX/vjrrGc2cvrLb30QVhyYox1j4Ll47y4QsSKp8RqVIaOwUhP+7B1K1TEBDn1esmqIbP17TZQdwuv7fejp0uCEOHd7X5eHl8L3sfMJLrQTv399uEAwpCaBygXnVBwBFesIDbpCkDVEXt6DB40A84yOtQpjetazPQpm0j+z3w3Dvv5zPkL46ReFxY4AxC4Cy4CQJmld/47aCRxCUYQQBD+mlIeA8KAgVBWCqqUvIDBcGPIOA0EQQHpw7cvLvbTugY9G3fM9N6ThcECAXOMcQ+OGo8YVJfe5+c9a/YAwddECAVeZ9xQn15b6/Sj2Zj6i/ScFAQCnYGuF5E6gWzNzg/XK/3AQM7WM8j7jjaI8/lC0JJa3Agj+M6Fnk/lG+eX2XvowuCPA55XLRstEpKKmftV7Vqiv16ec9wS2nsFISC8Q+kbp2CgH1w7vGX3+xVaPeIM/gYOSbTjp0uCHMXvmQ/fvfhAZ9B5pBhXeznAvku4bxGOKAghMYB6l4XhDKlS9mxu//osELbL1GihN3+5y8e6XqOeucuzezX9BvQzn6PcGIb7L7CAgUhcBbcBEFyPdq1xCAYQZD9ZV+UFAQKgs5DUWxLfqAgFCIIEhxpyCi37cq2koE/QcCFR3pHMmvecDt5uAmCfEbl1Ep2x0FB8E0SXv1R2hdf77EHeYjtRze22rG69N5rqkXL+lZMcHRQ4oTSTRAgk5/f2WXHEEeH/M0giCDgvd7/6HX7c6pUSVYYbOifFe62NHYKQuCDAb3O3QQBz0MSMto8b8UbA8PhI7vbcfMnCF892K8wayT5BDNY+md5uS0cUBBC4wCx0fO6LggSN1xzJrFFeeZc/gECeQ0FwTe3yykhoZZFcYpRpUoVVOuMvLaPOG/cMsVux4EIQpUqKT5nDeh5gIIQGT54ilHoeU76CgpCAIJw8swyO+mXK1vGvphUF4T0pnWsweDFd9eptRsmqcqV8wf7GDRK5+BPEM5dyrEvYMJgY86CEfY+sm+4pXRcPMXIt+HsPTjXjm/WjLyLkFHXOAIodVardppPPPIFIe8Uo0PHFlhclChR3N6nS7fm6pPfZpXwfm4zCFgdK3vOUJVUgTMIgQwQ2rVrbtWvFwLtr305BQExfevCarUyZ7yqXj3vokWcFnj0ZP4Fi7ogoMMHH7iNGNXd5gOnmui5wd/nR+pxSfoUBN/2H0z9FiYIeC/JGSgpCJEZ7D0rNxSFIDRpUtvK5zjFSOKN2WjEPxBB6NajhVq8fLQ184j9K5Qva1/LQEGIDDMUhNDznPQVFAQ/gtCgQXWFUwOwuox+Xnn3zJbq2me5ViLQBQEwotE3blzbThho+DiqqK9UogsCTinK+4yXFFZEkETTsGENdfrsCp8BaTCdmL/XyvtTEHwbzrFTi1VKSpJd/6i/b384Yq1YJHW2Zfs0n3iIIMjzzjIlOcmeaZJ46IKAVbEQ+/Gv9FU1alS2P/v552v6fI7sG04pjZ0zCL5xD7ROnYKAi89r1UqzY4bY4/oV/f10QXCyIfe37JiuHnEVo6AvSpXBYqtWTawYRFMWKQiRGbxJDCNRFpUgQO5xkbK0Z1yLhhwQqCDgQIPkZpyiOOrlntb+FITIMEZBCK2/A8PCJQXBjyBIo9dLXJSItYtlIKALgv462cYgMJhlTrEflkGTaxzkcyJVyveiIPg2HMRIP7KLc8ux/Fyd35Y3Rb05Y1CYIFSoUE61a99Yvf/x6/a+uiBILJzlqTeX2693fmao96WxUxB84x5ofToFwRkznHL4zXe+/5MSiCDg+gX8B0ag3yPc1wkHnEEIjQPUPwUhMoO3SIiBvEdRCQJ4wAIj1arnrXKHWWDwEaggYH8sg4rTlZBTUlMrqU25U3kNwtPIMEZBCD3PSV9BQQhQEHDUEBew6rMBTkGo36C6fTQBDV6/OFk6d30GwTnQqFevmsI0pb8/7JL3CLWUz6MgFGw4OAIs9dO0WV11+PhC+36HjvmrF0ndiyDgyA+WJsS1C3KT90GpX2vwLEHA0rbO1Szks8ItpbFTEArGPZC6dQoCZvjKlilt8/GNy5+l6YIwOWuAzQaEEfeFEZyiFMh3iMRrhAMKQmgcIAYUhMgM3mRwH4myKAUBTOBCc7k4vVefDDV2Qm+7ffv7HwScbSBtuk27RvbrsdBBv99mJfg/COGxRkEIPc9JX0FB8CMIsoqRNGK3UhcEWcUIAoGGLQMAfYCI99AFQVYxcntvLx6T70RBKNhwcB1CjZp5p/rg+pF9h+bZMXQbuOcLgu8qRojb7PnD7X1xPYpIpS4ITi68iLe8pzR2CkLBuEsdPat0CgJei1POSpfKW/4W7Qq5QH8PXRD0VYzwGlyLIG0Rpb6fl9vCAQUhNA4Qm8IE4Z0P1tuxxfVq+oyzxJYXKYc38HNKRVELwp37+xVmjPU2LduBCAJWMJTX6yUFITxOYlkQ8Ce6PXu1VmPG9Ypa/pf8E0gpfQUFIcKCgJVsRo7uYTf48ZP62gNEBIaCEFqj92oVI72x4OgPEjSODrfrkHd+M64lkOVr9df6EwQscSsr2+C91m2cbMefghBa7PUBQSxcpAwOvnpwQA0Z3sVu5737tlGPfs4fePoTBCxru2BJ/ipGYETnysttSfoUhPw4BVvf/gTh1t091p8oypFkxBWrVX335FiB+FIQws8Dek4oakEAQ842jfjjFoggYP/pMwfbuUT2pSCEx0msCsIHH7+uunRtprCgCWIMWQg2D3n9eukrKAgRFgQEDqcJderc1G7wWOdeAkpBCK3RR0MQ8N8V+lFhJOpJU/oXOL8csRRBwICgfccmCn98hps+MMT++kwBBSG02OuDgVgRBDCw9+Ac+1+2Meuk/zGWzgEWNhA+9FPZwMfAQZ3s3CA5wqtSkj4FITKCgM5d4ooLS+W/TBDXxk1qqzPn8v513RlPCkL4eUDPCbEgCIixvpgJGMAtUEHANUy4/lD2Q0lBCI+TWBUELH2O/CCxnjF7SNT6AGcu8ndf+goKggeCgFkEXH8gAKCUf1mlIITW6KMhCB98stlneVrETV+fWm9MIgh6jJ3bw17qpvA/C7IfBSG02OuDgVgSBMR14uR+9lKFzzeqpd54K2/1MV0QnFzIffzHhqyIJox4WUrSpyBERhAkjs6yZq00axlcf7GkIISfB/ScECuCcPb8Kp8+H1wEKggYM+CCZ50lCkJ4nMSqICDWG7dkWdeu4PoVfebZX86I9uPSV1AQPBAEBBPnJb44uJPd4Dt1aWYNFCkIoTX6aAgC4latWt6KFEjUTdLrWKsZuTXOZwlCjRqpVrK/fX+fLQd4DwpCaLHXBwOxJgg4f7hs2TJWO8cF65gtxDUnzxKEMmVKq1envmD94/r3PxU8BcWNt0g8JkmfguCNIHTt3kL99epG9dFvy2D7ixkFIfw8oOeEaAnCiTPLFBawwGyh28IVX327X42d2Md6Hq/BTV+REDOMdetWtR4fOKijT98AVm7c3mmtYCT7Vq2a4jMr6Y+ncB7HEsHo63pkdgh5uWE9FrG0HauCEE68orWv9BUUBE0QolX5RfU5cnSCFymHPkAoqtiF87nS2HmRsllxdzIjHFAQzOYAXAgL8xdkx/3AMFqC4GxPiXCfgsBc4Max5AcKAgUhLjqIaM0guDWWeH9MGjsFwezOQDigIJjNAfKZsEBBMJsFCoLZ8fc3tpH8QEGgIFAQEpwBaewUBLM7A+GAgmA2BxQExl8GhhQEsiAs6KX0FRSEBB8c6kHnKUZmJgNp7BQEM+MvOUA4oCCYzQF4EBY4g2A2CxQEs+MvfYOzlPxAQaAgcAYhwRmQxk5BMLszEA4oCGZzQEFg/GVASEEgC8KCXkpfQUFI8MGhHnTOIJiZDKSxUxDMjL/kAOGAgmA2B+BBWOAMgtksUBDMjr/0Dc5S8gMFgYLAGYQEZ0AaOwXB7M5AOKAgmM0BBYHxlwEhBYEsCAt6KX0FBSHBB4d60DmDYGYykMZOQTAz/pIDhAMKgtkcgAdhgTMIZrNAQTA7/tI3OEvJDxQECgJnEBKcAWnsFASzOwPhgIJgNgcUBMZfBoQUBLIgLOil9BUUhAQfHOpB5wyCmclAGjsFwcz4Sw4QDigIZnMAHoQFziCYzQIFwez4S9/gLCU/UBAoCJxBSHAGpLFTEMzuDIQDCoLZHFAQGH8ZECayIKSlpSgcFN1/eJ6S38syMPabNqtr1d2hwwciPj4s9vTp04i/Kd7z5s3PrS+NoDPQgQVaryeZQbh9+wtP4uNV3PG+LVo0smJ/6s3ljH2QQiMDwxUrFsZd3J1MdezYyuIAHZvONrcLzwfCwbx5M+KeA3DRpk1TshBkLpB2IiwsXjwn7lmYOnUiOQiRAxGEnr06xT0Hzr6iSZP6FhfTZw1hXxEEH3e+3W/VG8aLFy9eiDgXngnC999/b3/xc5dzGPQggn7m3Cq77n799deIB93ZOCN9v1u3Dtb3X7ryZcY9iLhjQFC9eqpVd1u3bY67uDs5GjCgp/Vbho7oSg5C5GDdutVxzwG46N27K1kIkgERBMkJmza9FvcsLF68wOKgR8+WzAlB8jDgxbx+deTIQXHPgbOvGDJkgMVFl27NyUUQXOw7NM+qtxIlSiiMuZ31Gu59zwQBXwxfGmaz5rWJDHoQQV+yYoxVb0lJ5SMe8HCBCWT/YcNetL7/oCGdGfcg4v7VgwNWvaHNnDp9Mi5jr/Mxfvxo6/e0bdeYHITIwf4D++KeAzAxevRwshAEAyIHek44cvRw3LOwefPrFgcpKUnMCUHy0LxF3lH27OysuOdA7yewnZubx0XFpPLq48+3kY0A2ZBZpZatmnjChKeC0L593ikGI0Z2Z8ADDDg6hiHD8462de3a3pOgOxtnpO+vXbfG6gTqN6jOuAcR9/PvrLXqrWTJkp4cDYh0nAt7v63btli/p2rVFHIQAgcQxTt37sRlDnCysen1DWQhCAZEECQn4GDb/fv3456Fa9euWRyA7bMXVjMvBMFEcnKSVXdenGvubK/Rvo+j38mV8n7f8JHdyEUAXLzz/nq7LW3cmONJbvBUEDA9jkSQlFRO8TSjws87Rqdw5YMNVn2h3ja9vt6ToHvd+O/d+8aePVqxZhwbewCNHbGfnJU3zdq1a5u4jLuTqx9++EGVKV3KygHkILD2r3PQunV6QnAALr777jsF8UVeIwvBs9C+fYuEYaF+/VoWB127t2DfEGDfsGTFy1adlStbVsXjacfOvsHt/sKFs6zfiBzx7tWNZKMQNlq1bmjVV40aVdXf//53T/KDp4KAAUKVKnnnVONCKzkqwtJ/ByEXpFWvXkX97W9/8yTobo0z0o+NGTPMbuxXr29h7Atp7EdOLrLr6+1zZ+M27k6OpkwZb/8ucuC/3UtO1Dk4/Ub8n2am8zBxYt4pZxgAkAVzWdi5a7udE6ZlD2bfUEjf8NGNrXZ9zZ07M2H6Bj03YPvHH39U9erVtH5ro0a1yMUzuJBTi5BLjx076hkTngoCgn7k6EEb7t37ZzPozwi6HEFG0OP9HHRMGVaunLd0WY0aqYz7M+KOwSFijtuoUUM8a+zOhByN+zhIUKNGFeu3kYPCB4XCwcCBfRKKA7AGFqpVq0wWCskFIovCwtChLyQcCz0yO9k5T34vS/f8UK9eNauunn++XsJx4OyDrl+/rpIqlLPZOHh0AccOWr7AzEqz5vXs+pkzJ9tTJjwXBAAw4qUX7B/EJQ8LJoG7Dw6oNm3zlgZFpzBu/EueBt3ZKL26/8aZ03bca9JP6k0AACAASURBVNVOU+9/tImNXWvs6BBxBE0GAjVqpKnHjx8nROx1ps6df9s+5QwXJ/J0w4I5YNmqsTYHqanJCXENis6AbIMF4Z05oSAHzpxQtepzCZkTcMpZzZp5Bw7AQ+6O6ewbHH2DfpS4UsUK6tatWwnXN0he0Mv33vurSkmpZOeJl0b3UOs2TlZYNv3W3T1GcXL/0WGFaw1wcH3RstEqObmCXS/Tp0/2nIeoCMKTJ09UenreFfhIBjh3CsszffHNXqOC7TxCcvvePivwuIhTOs3mLRqqn376yfPA6w3Sy+3s7Fft34bfuDJnnLrGU46sC/RwDq7EvVzZMuqdK5cTJu5OppYvn2//VvzmrBmDrMTnbBOm3cc1R+gAhQOUZ996M2E5ABcLF+Wfa4zfy5yQJwq4aFfPCaib8+ffTlgWcLS4evU0m30sfZqz/hX19qU1xo4LcIR4/eYp9r9ngwEcUb9w4VzCcuDsK3D/888/VxkZ+f0j6oG3vDrAxdxbtrweFR6iIggIOKaXO3VqXyDI6U3rWB0kbNmU2+ixPZUsWaZD361bx7i+7sCtoeOxlatW2EeQ5ffWrVtV9X+hvTExF7bRCeIoutQDSpyK9eGHH0alwfuLUTQez926RZUsmbf0sfx+nHbUp19b4zjo1SdD6QcGUB84avbee+8lPAdgbcPG9cwJv/V5/nKCCSx88803qkWLZj75EG2hQoVy1iAZ1+SZcktLSy5QD3Xq1FAff/yxETnBrQ86cuSQGjSoj30tq/Qb0S7/+7//u0Bsov0dOnRopZYsmRvVGcWoCQKCjyutc3O3KFx1He3Kdfu8v/zlLzHxPWrVqq527Nim/vd//zdhEwE6u06d2sVEfbuxUBSPlS1bRk2bNlk9fPgwYePuTPro7Hr16kYOtCNipUuVUpMmjVPffvutMRyAC0hx9+6dyYLGQpnSpdWUKRONyglgYdfunaply3Sy8BsLuN4gJ2eVUfnA2Vc47+O0tKtXP1Rvn3sr6rdZs2ZG/TPxOy+/c6lIl7qOqiDoAX/33XfVqtUr1Pjxo1SvXp1Vx06ton6rXDk56p+J39m7dxc1YcIYtWbNKmOOGErsv/jiC7Vt+1Y1ffqrauCLvYuk/tObNiiSz+3ara166aXBav78OerUqZPWqg1SL6aV9+7dUzt3blfZ2VPUiy/2UZ06ty6SmBRF3unata0aPuJFNXfuLHX8+FFrdtW0+Ou/9+uvv1bbd2xTM2ZMMS8ndG2rRowYpObNm61OnDhudE4AE48ePVJvvnlGbd6y0ToVbf78bBXt25w506L+mfMXZKuNG1+z+gXTDhTouSBWt0eMGGFk2ywyQYgFENq3j88/IouFuovn77BkyRIemXn61Pg6uHz5shGndsVzW43Wd2dOYD4Aa2+99ZY6fvy48bkxWu0uXj4nNTVVHT4c//9kHmx9Gy0If/rTn5gIDBwoduzYUV28eJGxNzD2eoKcN2+eWrZsGTkwnAMwwZxAQQAHM2bMUJMmTWJOYE6wGbh7964qVqyYGjdunP2Y3o8k8raxgnD16lUr6CgTOcD8bQU7vv/4j/9Qc+bMYdwN7wQyMjJU586dyYHhHCBHMicUzJMm9h1NmzZV9eol/v8NmBjbUH/z5s2brbFirVq1jOsrjBWE1atXW0FHGSo43C/+OhURw1atWjHuBg8MsSDAv/7rv6o///nP5MBgDpDDmRPiL4971ff+wz/8gzUuMGnhCK/qMlHed+DAgRYTmEX49ddfjeovjBWE7t27W0FHmSgg83cU3tHl5ORYcf/DH/6gfvnlF8be0MHhmTNn7KTPWcTC200i5xbmBLPjL2yfO3fOzgn79u1j32Bo3yA8SFm+fAWbi5MnTxrFhbGCgHVtYYQoBQSWid9RZGZm2o391KlTjL2hncD06dNtDtauXUsODOUAOZ85IfHzfiB9+4IFC+ycMGbMGOYEg3OC8IJ/r8Y4UW5ZWVlGcWGkIMiUsgSdRxDN6SDwfwcS96lTpxrV2CXpsXyq0tPTbQ569+5NDgweDDAnmJP/n5X72rRpY+eEatWqMScYnBOEk9dee81mAuOGRo0aGcWFkYKAI4YySETJI4hmdBBOMWzcuLFRjV2Snukl1lr//e9/b+eAkiVLkgNDBwPMCWbk/kBy3h//+Ec7J2Bc8OWXXzIvGJoXhJdevXr5MAEu5DkTSiMFoX///j5Bx30Tgm36b3SK4e9+9zvj/rHUdAbw+w8dOuTT/pH0OYto5kCROcHMuDvzoH79AfIBblu2bOG4wHBBKFGiRIG+4uzZs8ZwYaQglC1b1ifouO9MGLyfeB3HgAEDfOKOTmD//v2MvWGdwIQJEwpwwFnExGvvgeRw5gQz4+5kQ7/+QARhyJAh7BsM6xt0Lj799NMC/QTYmDlzpjFcGCcIzillSQY8gpj4HYW+GoHEfezYscY0dj35mbxdt27dAokfA0WT68TU386ckPh5PxC2u3TpUiAnJCcnMycYLAirVq0qwATGDS1btjSGC+MEwTmlLANFHkFM7I7CnxjWrl3bmMYeSEeZ6K/56quvXJN+UlISOTBsMMCckNg5P5hc9p//+Z+ueeGjjz5iXjAsLwg3btKI8SKWSJfXJHppnCC4TSkj6DyCmNidhT8xROx5MVpix15P4tu3b3cdCIADziKawwGYYE4wK956HtC33a4/QD7Abc2aNcYMBvU64fZT6080hQNnefHiRSO4ME4QMG3oDDbuczoxsTsLf2KI2Ofm5hrR2Jn0n6rhw4e7tn9wwFnExM4BTv6ZE8yKtzP+ct/t+gMZI3AJZDMZ+fDDD/32E2Bj/vz5RowZjBIEf1PKkgx4BDFxk4E/MUTshw4dakRjlw7R5LJKlSp+Ez9nERO3/bsxz5xgVrzdGMBj/k4lQd9QpkwZ9g0GnmK0ZMkS9ac//UmNGDFC7dmzx+ozFi1apPBHaWlpaapt27ZGcGGUIOhTyg0aNLCCXrlyZXvAwCOIidlh6GJYunRpK94VK1a0EgA6gdTUVCMau78O0pTH9VUphANcpIqOABxwFjEx278b3245oUKFJJsF5gRzWMBSlsgB7du3V02bNrVyQd++fZXkiMuXL7N/MEwSBg0apD777DM77ugfTp8+bd3/5ZdfVHZ2tv2cW35JlMeMEgQcIcRfqN+8eVM9fvzYSgRPnjxRGDjgcR5BTMxOAeKXmZmpLly4YDVqNPYNGzZY2zg60KRJE8WL0RIz9nqixr9iOjlYtmyZDwecRUx8DsCEW06Q882ZE8xgABzg+gMsW3n37l0rD8yZM8caF0jeQM5YuHCh9Zw8xtIcPiTWuiDIY8KM3E/E0ihB0AOoC4L+OLcTv/HrgiDxfvDgATsBw44SgQMRBHKQ+O1eYuxWggURBHmeOcE8JpyCICywNI8FPeZugqA/n6jbFIQnTzgwNHBgKDMIidqw+bsK79DcBIH1Vni9JWIduQlCIv5O/qZn801BeHb9mMoPBcGwQSJnEMxNBGjsFARz4y+dHAWBDOgsOGcQ5DmW5nBCQTAn1sG0awoCBYEzCYYwQEFgJ4DOgYJADmSQABYoCOQBgtCvXz+OBQwZC0j7L6ykIBgGBGcQzO0MKAjmxl7vCCgI5EB4oCCQBbBAQSAHkhP0koJAQeBRA0MYoCCwE0Dyx/rnzouU9U6B2+ZwQkEwJ9bPatcUBHLgxgcFwZDBoQSfMwjmJgIKgrmxl/aPkoJADoQHrIHPU4zIAwWBDEhO0EsKAgWBMwiGMEBBYCdAQSAD+gCAgkAewAMFgRzoeUG2KQiGDA4l4JxBMDcRtGzZkqsYGdbepd3rJWcQzM0BOgfYpiCQBXBAQSAHztyA+xQEwwYMFARzEwEFwdzY68mfgkAOhAcKAlkACxQEciA5QS8pCBQEnmJkCAMUBHYCSP4UBHIggwAKAlkACxQEciA5QS8pCIYMDiXonEEwNxFQEMyNvbR/lBQEciA8UBDIAligIJADyQl6SUGgIHAGwRAGKAjsBJD8KQjkQAYBFASyABYoCORAcoJeUhAMGRxK0DmDYG4ioCCYG3tp/ygpCORAeKAgkAWwQEEgB5IT9DIlJUWdPn3auIPIxfRKMGmbgmBuIqAgmBt7PcdREMiB8EBBIAtggYJADiQn6CUFgTMIxtmh3gBM2qYgsBMA7xQEciB5j4JAFsACBYEcSE7QSwoCBYGCYAgDFAR2Akj+FARyIIMACgJZAAsUBHIgOUEvKQiGDA4l6DzFyNxEQEEwN/bS/lFSEMiB8EBBIAtggYJADiQn6CUFgYLAGQRDGKAgsBNA8qcgkAMZBFAQyAJYoCCQA8kJeklBMGRwKEHnDIK5iYCCYG7spf2jpCCQA+GBgkAWwAIFgRxITtBLCgIFgTMIhjBAQWAngORPQSAHMgigIJAFsEBBIAeSE/SSgmDI4FCCzhkEcxMBBcHc2Ev7R0lBIAfCAwWBLIAFCgI5kJyglxQECgJnEAxhgILATgDJn4JADmQQQEEgC2CBgkAOJCfoJQXBkMGhBJ0zCOYmAgqCubGX9o+SgkAOhAcKAlkACxQEciA5QS8pCBQEziAYwgAFgZ0Akj8FgRzIIICCQBbAAgWBHEhO0EsKgiGDQwk6ZxDMTQQUBHNjL+0fJQWBHAgPFASyABYoCORAcoJeUhAoCJxBMIQBCgI7ASR/CgI5kEEABYEsgAUKAjmQnKCXFARDBocSdM4gmJsIKAjmxl7aP0oKAjkQHigIZAEsUBDIgeQEvaQgUBA4g2AIAxQEdgJI/hQEciCDAAoCWQALFARyIDlBLykIhgwOJeicQTA3EVAQzI29tH+UFARyIDxQEMgCWKAgkAPJCXpJQaAgcAbBEAYoCOwEkPwpCORABgEUBLIAFigI5EBygl5SEAwZHErQOYNgbiKgIJgbe2n/KCkI5EB4oCCQBbBAQSAHkhP0koJAQeAMgiEMUBDYCSD5UxDIgQwCKAhkASxQEMiB5AS9pCAYMjiUoHMGwdxEQEEwN/bS/lFSEMiB8EBBIAtggYJADiQn6CUFgYLAGQRDGKAgsBNA8qcgkAMZBFAQyAJYoCCQA8kJeklBMGRwKEHnDIK5iYCCYG7spf2jpCCQA+GBgkAWwAIFgRxITtDLYsWKqdOnTxt3ELmYXgkmbVMQzE0EFARzY6/nOAoCORAeKAhkASxQEMiB5AS9pCBwBsE4O9QbgEnbFAR2AuCdgkAOJO9REMgCWKAgkAPJCXpJQaAgUBAMYYCCwE4AyZ+CQA5kEEBBIAtggYJADiQn6CUFwZDBoQSdpxiZmwgoCObGXto/SgoCORAeKAhkASxQEMiB5AS9pCBQEDiDYAgDFAR2Akj+FARyIIMACgJZAAsUBHIgOUEvKQiGDA4l6JxBMDcRUBDMjb20f5QUBHIgPFAQyAJYoCCQA8kJeklBoCBwBsEQBtDYN2zYwHgbEm890evbFAQOBoQHCgJZAAsUBHIgOUEvKQiGDRY4g2BuIqAgmBt7PelTEMiB8ICcsGbNGh40MGwcIPGXkoLAnCAs6CUFwbDEQEEwNxFQEMyNvZ70KQjkQHigIJAFsEBBIAeSE/SSgkBB4NEjQxigILATQPIHB8uWLWO7N6Td6x2+c5uCwJwAJigI5MCZG3CfgmBYJ8EZBHMTAQXB3NjryZ+CQA6EBwoCWQALFARyIDlBLykIFAQeSTSEAQoCOwEkfwoCOZBBAAWBLIAFCAJYEC5YkgswACZOnz5tHBfFTG0AnEEwt+GjsXMVI3PjLzkPHPAUI3IgAwBepEwWKAhkQPoHvaQgGHL0WIJOQTA3EVAQzI29tH+UFARyIDyABQoCeaAgkAHJCXpJQaAgGDd9pDcAk7YpCOwEwDsFgRxI3qMgkAWwQEEgB5IT9JKCQEGgIBjCAAWBnQCSPwWBHMgggIJAFsACBYEcSE7QSwqCIYNDCTpPMTI3EVAQzI29tH+UFARyIDxQEMgCWIAg/Mu//AsPFho2HpQ84K8EE7xI2TAorl69ykRgWMyRABD369evM/YGxl7vAMDBtWvXyIHhHEhO+OSTT8iCxyx8/PHHirfw60DPY4mwTSbCZwJ1GGkWPFvF6MaNG6pc+fK8hVkHN2/ejHjQIw2R8/2aN2/OuIcZ90RYXadDhw7kIEwOZs+eHXft35kPcD8jI4MshMnCggUL4p6FrKwsVbx4cd7CqIPMzMy458CZI1JSUshEGEygTe3evTviXHgqCEwE4SfCeBUExj682CeKIJCD8DhIJEEgC+GxQEEIr/4ShT8KAjlwYzluBeH86oWKt+DqQACIZ0HInTqBcQ+S/Z6tm1tHUhJJEHImjiIHQXIwuFNbi4NEE4QNk18mC0Gy0L9dK4uFRBKEkd07qR+P7eQtiDpYNmaYxUEiC8KZpXPIRBBMoA01qV3T4iJuBeH7w9sY9CCC/uBArhVwSEK8CwI7geA6wUQVBHIQHAeJLAhkITgWKAjB1Vei8kVBIAdubFMQghhcu1VgvD1GQTA3EVAQzI29nqcoCORAeKAgkAWwQEEgB5IT9JKCQEGI+MUnzouEInkfFylj9gOnGOkgc7vwBEdBKLyOTOCIgkAOhHMKAlkACxQEciA5QS8pCBQECoIhDFAQ2Akg+VMQyIEMAigIZAEsUBDIgeQEvaQgGDI4lKDzFCNzEwEFwdzYS/tHSUEgB8IDBYEsgAUKAjmQnKCXFAQKAmcQDGGAgsBOAMmfgkAOZBBAQSALYIGCQA4kJ+glBcGQwaEEnTMI5iYCCoK5sZf2j5KCQA6EBwoCWQALFARyIDlBLykIFATOIBjCAAWBnQCSPwWBHMgggIJAFsACBYEcSE7QSwqCIYNDCTpnEMxNBBQEc2Mv7R8lBYEcCA8UBLIAFigI5EBygl5SECgInEEwhAEKAjsBJH8KAjmQQQAFgSyABQoCOZCcoJcUBEMGhxJ0ziCYmwgoCObGXto/SgoCORAeKAhkASxQEMiB5AS9pCBQEDiDYAgDFAR2Akj+FARyIIMACgJZAAsUBHIgOUEvKQgRHhx+uHGFemPpbPt2ddPKmPrHX84gmJsIKAjmxl5P+hQEciA8UBDIAligIJADyQl6SUGIsCCM6NZRFS9e3L6NzuxCQXj6NGKzFM2bN7fqNnfqhJiqV71Rxeo2BSE+OoEvd21Q7+QssW5esERBiA8OvIi98z0pCLHNwo1t69TKsSOs26nFszzr8ygIsc2Bs91G6z4FgYIQscH70wiKgL/3oiCEnsgoCKHXXbQSMj5nyeih9gGGx0d3RHxQQEGIDw6iwRwFIbZZGNm9k50LxvbsFvFcIIxREGKbA4lTtEsKAgWBghBhBqLdiAP9PApC7HcCH25cqdo0amAPCigIhc8+ZmRkWPW1YfLLng2gAm1j8fY6CkJs54TGtWrYuYCCUHgucDuwmJKSYtXhmaVzmB+CHOtQEIKssMI6AJ5iFFojdmvYbo9Fawbh7PJ5auPkl1XOhJHq3XVL1aMj20NKLnd2b1QH5k61rkl5fMT9aPAXO9dbrzm1ZJa6t39zSJ9TGJd4noIQ2mDg5vbX1P45Wer0klnq672vBxWfjzavVvtmT1HnVy1U3x/eVui+JxbPtAcEOFWRglB4PolVQXhwMNdiJmfCKPX6lHEq1q5HQ06gIASXE5DD0Rd8sGGFWjtxlFrx8nB1btVC6zG3PgLtF48/PLhVvbl8rpo19AU1Y3B/tWfWq373QVx+OLpDrRo3QlUsX97OB2Myu9j74D0jmRs4gxAcB4H0t4nwGgoCBYEzCMd2WoO3NRNGqnJly1i3MqVLq1KlSqlSpUoqbMvjbo3+u0Nb7efxuss5i62BoLVPmTKqdKlS9ns0qlVdfb59nfU8knKlCuVVWf01ZfI+3+1zwn2MguC/ExjSuZ0dw24t0q34jO/dXVUoV9Y1Ps/qnD/NXaP6tmlpvV/ZMqV94g8mTi+Z7SoKJxfPtDjRr2ES7qS8sm6p677BsMFTjPxzEEw9ur0WAzvMAEnbz8sjJa1cAhbw+PCuHawBoNv+0X6MghAYCz8c26mOLpihkBv09uncvrXjNbt9frZtrerVurkqUaKE330a1ayuDs+fpu7tyz8whO1J/Xr63Uc+ExxFihcKQmAcRKq+4+V9KAgUBArCsZ3q+tacQhMyEjMGjHit3sAhCJK0Ue6e+arPff05bHdu2tgaJEBAnM/J/SopldS3B7b4fI7+maFsUxD8dwIvtG9tx6JWlcqqe8um9n2JibN0m01AZ+98ndv9junPq7t7NtnxrV2lckD74eLlUGKv70NB8M+BXk+hbL/av5d1UMEt5vpjOBr8lRb/UD4rEvtQEAJjAbMFevz8beszwJglqJ76XKH7pVZMUkcWTLfbNVZB9Pf++uMUhMJnF3EWAk8xCoxxt3xCQaAgUBCO7VQ4Fah9k4ZWYq6WmqIGtG9trRffp01Lhft6Yu6Y3shO5mhUTkGQ15YvW1a1alBPVa5U0Wd/eR4ljjB2aPK8eq5iks9rypcto1aPH+nzOW4NOJjHKAj+E6UuCHp8EJcuzZqotORKPvHBa7Je6OMTH5xCpO8r260a1FV1q1Xxea5M6VJq+qB+9v7grFm92iq5QgWf1zWvX0e10G6ROE2FguCfg2Dak9tr31u/XNX7LdY101LVoI5trTzyQvsMVbJkSZ/YHpo3TeHItNv7ROuxWBCEmzdvRqQPysrKsuoXF/ZGsv70pcGlTaNETAe0a62SypezPrd3Rgv18NBWn8/u2jxvxgEzxUtGDVHrXhlt3ZKTfNs52j/6IHzv99cvt7hxHjQAV+BJbusnjfH5rHB+cyzOINy+fTsiXFAQQs8xFIQIJ2heg+Bu9deuXVOjRo1SBw8eVE+ePAm54Xt5DcK111dZK8jsnTXFGvQj4X6zb7M1kCtXpozduQcqCOgMcErI9ukTVa20VHt/6WSQ6FePf0l99Poq63qHNs/X93lNZqtmEesA8FtiQRAixUGHDh2susqZOCoideQmCIM6tlFYTvezrWvVzhmTVL+2rXzi07RuLZ/PfnVAb5/ncYHhgpcGqStrl6pjC2dY53vrHDWsUU29uWyu9R4YFLy9coF1SoLwgfLimkXWKWs4bQ03nNcezkAA+8aKIESKhVi7BmFL1ngrj+DaI5xyhDqHPM4dPtCHjwl9eth5JtyYhrp/LAgCjvJ26dJF9e/fX23ZskXdvXs3pP7BK0EY2CHvInhplylJFdS2aRPVrZ3rFU4pupyzRJ1fvdA6dfSHo76DMQg9nntn7RKfa5BwX94PJeQR1ysJK7guDQKivwYzBnhcbvpsRajxl/1iURAwTqhTp44aO3as2rt3r3r48GFIXFAQfJmUmAdSUhAoCCE1OrcLiAt7bNKkSapYsWLWrVatWuqVV15RJ06cUL/++mvA38FLQfDXYC6uWWwd3ZVkndGwns/pIW4zCCcWzfQZyI3q0bnAuahH5udPKz8+sl1NHdjHp0NIREEAI5HgwGtBwKkBGNTrTOBiU2EApVMQ9ME/nt88ZZzPhYRY07yttkIRBgVzhg20PwMXMo7u0dnnM551rYP+3YLZjhVBiBQLsSYI/mLx3SHfGSacRuh2mpq//b14PFYE4cKFC3bfgD6iYsWKatiwYWrXrl3qwYMHAfUPXglCep1aPm0SeSASMz96LsE2DhTpMR7Wpb3P55q4ihEYkDHDP/3TP6nGjRuryZMnq+PHjwc8bqAgUBB8GpbeyKK9zRkE9xkEDAYuXbpkN3Zp9FI2atRITZs2Tb355pvP7AyiIQiY+sfRdkwD44aVJPTTA1rWr2sdORK23ARBjhzKa3A+qn7NQf3qVQv8EdaMwf18OoREFYRIcOC1IOACZeeqJMEKAlYkkvhLiZjqA4Pswf3t15goCJFgIVYFAbNP7Rs3tPOI87QSXLB8N8hVsYSjSJWxIgjoH5BjpT9wllWrVlVjxoxRBw4cUI8fP3btI6IhCPiOwZza88mW1dYsMmYcMp6vr5wHEfRcQEEoOHbYvn27Xyb++Mc/qpYtW6pZs2ap8+fPuzIBrigIFAS7k41U4gz1fSgIBRs5GiluP/74o9/GrncI//iP/6hatGihZs+eXaDheyUIl9YsVul1avoM3vTkrW+HIgg4zQTXG8j74OgQ/jFX58wUQYgEB14LAlYR0WOD7WcJAo70650/zj+/sHpRgfeQ07yEA9MFIRIsxIog4Fz144uyVa20wC44pyD49hU4SKT3A8/arlu3rpo4caI6duyY+vnnn63+xQtBwKlhcpoF2ixmfbBssTM3OO/joBEuNsaqddLWCytjRRC++uordefOnZi5PYsD/bm//OUvqlOnTmrZsmXqgw8+sIWBgkBBKLTBOhuwV/fjTRB+97vfBZyUC0twemON5Pa//du/qbZt26qFCxda5yTie+DoXKRiiOXo3H5bz1bNrPPOe7Rs5nOhcSQEYULvHuqbfb5r6kdTELp27Rpw3CWWbnXkfExe60Wpc4CpZny2V9cgBCsIGBxiGUupD5yihP8+cDKK6xhKlChuv66oBeGFF17whAPUgxcMyHvqLDRokPfHckX9R2m4TgXnpwsDKKukJCvMGiHuzmtYYk0QghmgSxxipcR3x+3Pf/6ziuRFyjgtTBcELFawNwBBeGvFfIVrjJwsIK+sHDvCuunPYTtWBGHlypVht93f//73Sr8VBSelS5dWffv2tWLwX//1X4p/lBa8KAj7u3fvtoVLDviGWxYL9w387X/jxg274QXy50POTtrL+/EmCFeuXFHRvAWTKHBEoHPnzmr58uXqww8/tAD1YgZhSKd2Nk9I1BkN66tZQwcoDPrAyqe5OQrLUkpCj4gg9ClaQYhmzN0+K1wOYm0GAZzoMwgY/Ll1SLF2ipFbbKL9WLgsxMIMAlagwXVGkiNQQg52ZU9S3/6WR8CI/nysCcIbb7yhgrnhdNB3NrDPBwAAC3tJREFU331Xffrpp9aFxf5O/fHXjzsfr1GjRkAD03/+539W6Admzpypzp07Zw9cvJhBQMz0axACOcUI1yfglCI91hALLDiARS/wnk4W8NpYEQRnXIry/r179wJiAjmkXLlylhCsX79e6StjcQYheDEQRikIvEjZTrBeJ4KrV68+s7HjHP3MzEyVk5NjdTpu38cLQcA61Hoy3/TqWJ/zz3H9gL7UaSIIglvdRuuxSHAQ64IAniJxDYIXB0Bi6SLlSLAQC4KAUxSxlKWeR/DHd9LRosSMof58rAlCtNq/v8/BASE3Wfz3f/93awZ5/vz56p133vHbX0VDEBC/tRNH+8RVjzG2IYRYwliPNWaPnK/Tn8c2BcH3lDNwsnbtWlcmwElycrLq16+fcgqBky8KAgWhQONzNsZo3Y+3GQRnY/LyvnPqMikpSQ0YMEBt3LhR3bp1y2/i179TNAQByxPqvCwaOdhnBSIKQsFErseosO1IcBCLgoDlb/VOH/+hoK9Ss2jUEJ/rUPCnezjdQFiDDMwcMsDnPYZ2bm8/L68Lt4wlQYgEC7EgCFiiVo89tm87rjHCdSn6aygI+XkEqxWJHPzP//yPwimQS5cu9TmXvLC84pUguP178q7syQpLmMrt2MJs1aBGNYWlR3H9AfoMPdYt6te1cgHaOP5os07VNJ/n8drCBAHLYmMpbvlMzGyHmwtk/1hc5hTx7t69u81FtWrV1ODBgwsVAicnsSoImHXUz17A0rcSj1gpOYPAGYSABubORhfs/UePHqm0tDQ1fPhwtW3btpDXuvZCENySNVYywlFB+aMbPdlTEPI79qLiIBYFAUndeRRZ50bfLlGihLXOubMjwPK4+uuwjYvbU5LyZrkS6Z+UI5UTYkEQcB2T8/QxXKyMC1X3z8lyvXCZgpCfR/r06WMdLf7kk09C7o+8EgQMxJ1t0t99+W+CnTNe8dkHbfilbh3VirHD7T/Sc76HUxCw7DX+UFF/XelSpeyDVTj1yZk/Qr0fi4LwxRdfqJEjR6rc3FyfU4aC7XNiVRBwHaUe27pV0yIWz1A5cO5HQaAghJyQg2moof7JifMzvBCEwv7avkblVIWLTjGoQ4OmIOR37M74FHY/UhzEqiAcnDvV9eig3hFgu3XDetafJzkTMi5uTH3GP28nkiBEioVYEATEERdJ60sZO2MOeUTc5XEKQuh5xC3PeCUIiK1zRkBi6CxFEHA0uFWD/Fg7X4f7uM5Nf9wpCPhX7lpV/K+IleiC4BbjUB6jIPAUo5gxL55iFNmk70wIXggCOoCJfTJVqVIlfRI2kjdmF/bNyVK4DkGuVaAgeBtjZ8zd7seqIOAUgqMLZvgMBPVBALZf6dvTdQlUcHh3zya18KXB1nKKzv1wP5EEwS2uoTwWK4Lw7rplamjndgqnjjlj1zujhbXiFpa+lecoCJHNI14KAi48Rh/QvUVTO34SRymXjRlqX7uG/1BBrOUIrLwGJR7De2GZa/1xpyAgH+CAgf4afRszVnhNJG6xOIMQSi5w2ydWBWH79Fd8xhycQfhtPXy3IAbzWCyvYoSVCtD45XYpZ3FEGnAkkgDeAyvzSJLRr/QPpv6L8rVeCcKDg7m2CEjsUJ5dPteOHwZ+eOzUklnq4aGt9uNYA1/fB9vOeOFcdKyfLa/DEabvD2/3eR2OGMnzKNE5ON8nnPuyBj/WiS7KGEbisyMtCOdWLfCp+yvrlhao+4+3rPZ5jfMiVD02GCzqsdS38Ydo+mud25AEvLe+j2zr1zQ49wv0fixdgxAJFmJFEFD/N7avUzg9UeIlJc47x/M4wiyP4cCDFxehB8oBXhdLf5QWLgteCgLqCn9+eX//FoVzx91uznyO12PVIudr8Riew01/7vGRHa55QX+Nvi2zFcHE299rKQiRES1/9ev2OJbQRTzR93y5c4O6u3eTa/zd9o3WYyK4XOY0QiYercCF+jkUhOgnglBjFen9KAjmxl5niYJADoQHCgJZAAsUBHIgOUEvKQiGiIEEnYJgbiKgIJgbe2n/KCkI5EB4oCCQBbBAQSAHkhP0koJAQYir0028OsVIbxSJuk1BYCcAtikI5EByHAWBLIAFCgI5kJyglxQECgIFwRAGKAjsBJD8KQjkQAYBFASyABYoCORAcoJeUhAMGRxK0HmKkbmJgIJgbuyl/aOkIJAD4YGCQBbAAgWBHEhO0EsKAgWBMwiGMEBBYCeA5E9BIAcyCKAgkAWwQEEgB5IT9JKCYMjgUILOGQRzEwEFwdzYS/tHSUEgB8IDBYEsgAUKAjmQnKCXFAQKAmcQDGGAgsBOAMmfgkAOZBBAQSALYIGCQA4kJ+glBcGQwaEEnTMI5iYCCoK5sZf2j5KCQA6EBwoCWQALFARyIDlBLykIFATOIBjCAAWBnQCSPwWBHMgggIJAFsACBYEcSE7QSwqCIYNDCTpnEMxNBBQEc2Mv7R8lBYEcCA8UBLIAFigI5EBygl5SECgInEEwhAEKAjsBJH8KAjmQQQAFgSyABQoCOZCcoJcUBEMGhxJ0ziCYmwgoCObGXto/SgoCORAeKAhkASxQEMiB5AS9pCBQEDiDYAgDFAR2Akj+FARyIIMACgJZAAsUBHIgOUEvKQiGDA4l6JxBMDcRUBDMjb20f5QUBHIgPFAQyAJYoCCQA8kJeklBoCBwBsEQBigI7ASQ/CkI5EAGARQEsgAWKAjkQHKCXlIQDBkcStA5g2BuIqAgmBt7af8oKQjkQHigIJAFsEBBIAeSE/SSgkBB4AyCIQxQENgJIPlTEMiBDAISVRA+27pW8RZ4HZgiCGQicCZQV3EvCGkpyYq34OqgePHiCrebN2/GlRw8ffpUNW/e3PrujHlwMZf6QtyXLVsWd3FH7PVbhw4dyEEYuQ8czJ4926dO9fqNp+2MjAyyECYLCxYsiHsWsrKyLA6kf2OZ188HUw+ZmZlxz4Ezd6WkpJCL38Z8wbCgv3b37t0R56KYM1CRun/jxg0GPMyAI/jxLAg6vNwOriNIJEFg7IOLvV5fiSYI+m/jdnBcUBCCq69E5YuCQA7c2I47QTh79qziLbw6iEdBYMzDi7nUX6RkvajeR34Hy/B4KKr4RfJzyUB4DEj9RTImRfFejx49UryFXwdFETsvP5NMhM8E6jDSMfJsBiHSX5Tv53v6BuuD9UEGyAAZIANkgAyQATLgBQMUBMd5015UMt+TjZcMkAEyQAbIABkgA2QgXhigIFAQIj4tFS/w83syUZMBMkAGyAAZIANkoCADFAQKAgWBDJABMkAGyAAZIANkgAzYDFAQCIMNAw26oEGzTlgnZIAMkAEyQAbIgGkMUBAoCBQEMkAGyAAZIANkgAyQATJgM0BBIAw2DKbZMX8vjwiRATJABsgAGSADZKAgAxQECgIFgQyQATJABsgAGSADZIAM2AxQEAiDDQMNuqBBs05YJ2SADJABMkAGyIBpDFAQKAgUBDJABsgAGSADZIAMkAEyYDNAQSAMNgym2TF/L48IkQEyQAbIABkgA2SgIAMUBAoCBYEMkAEyQAbIABkgA2SADNgMUBAIgw0DDbqgQbNOWCdkgAyQATJABsiAaQxQECgIFAQyQAbIABkgA2SADJABMmAzQEEgDDYMptkxfy+PCJEBMkAGyAAZIANkoCADFAQKAgWBDJABMkAGyAAZIANkgAzYDFAQCIMNAw26oEGzTlgnZIAMkAEyQAbIgGkMUBAoCBQEMkAGyAAZIANkgAyQATJgM0BBIAw2DKbZMX8vjwiRATJABsgAGSADZKAgAxQECgIFgQyQATJABsgAGSADZIAM2AxQEAiDDQMNuqBBs05YJ2SADJABMkAGyIBpDFAQKAgUBDJABsgAGSADZIAMkAEyYDNAQSAMNgym2TF/L48IkQEyQAbIABkgA2SgIAP/D4kXNMDsNHLoAAAAAElFTkSuQmCC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9bAczCkRaOJ"
      },
      "source": [
        "You're given a dataset witch consist of labeled data, dataset is split into `train` and `test` in **70/30** ratio.\n",
        "\n",
        "***Format of the data is the following:***\n",
        "\n",
        "```\n",
        "Dataset = [Sentence]\n",
        "Sentence = [Token with label]\n",
        "Token with label = (Token, Label)\n",
        "```\n",
        "\n",
        "***For example:***\n",
        "\n",
        "```python\n",
        "train = [ \n",
        "  ...,\n",
        "  [('I', 'PRP'), ('am', 'VBP'), ('not', 'RB'), ('a', 'DT'), ('cat', 'NN'), ('.', '.')],\n",
        "  ...\n",
        " ]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b8zi0TlTBuh5",
        "outputId": "c90b77b4-8019-4067-f9ba-62f498ba01fc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package conll2000 to\n",
            "[nltk_data]     /Users/k26609/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package universal_tagset to\n",
            "[nltk_data]     /Users/k26609/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# @title ☜ Download dataset\n",
        "# Download and parse the dataset\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from typing import List, Tuple\n",
        "from typing_extensions import Protocol\n",
        "\n",
        "TaggedSentence = List[Tuple[str, str]]\n",
        "\n",
        "def download_dataset() -> Tuple[List[TaggedSentence], List[TaggedSentence]]:\n",
        "  nltk.download('conll2000')\n",
        "  nltk.download('universal_tagset')\n",
        "  sentences = []\n",
        "  current_sentence = []\n",
        "  for word, tag in nltk.corpus.conll2000.tagged_words():\n",
        "    current_sentence.append((word, tag))\n",
        "    if tag == '.':\n",
        "      sentences.append(current_sentence)\n",
        "      current_sentence = []\n",
        "  return train_test_split(sentences, test_size=0.3, random_state=42)\n",
        "\n",
        "train, test = download_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDmcCpnxcBlu",
        "outputId": "0b377ba4-8f6a-41c3-e26c-fb419fe31b81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded: \n",
            "        train: 7561 sentences\n",
            "        test:  3241 sentences\n",
            "      \n"
          ]
        }
      ],
      "source": [
        "print(f\"\"\"Downloaded: \n",
        "        train: {len(train)} sentences\n",
        "        test:  {len(test)} sentences\n",
        "      \"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "5iIowjKrXw88",
        "outputId": "ee390758-efb6-49b0-9c0e-ecf379cddbda"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#</td>\n",
              "      <td>)</td>\n",
              "      <td>CC</td>\n",
              "      <td>FW</td>\n",
              "      <td>JJS</td>\n",
              "      <td>NNPS</td>\n",
              "      <td>PRP</td>\n",
              "      <td>RBS</td>\n",
              "      <td>UH</td>\n",
              "      <td>VBN</td>\n",
              "      <td>WP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>$</td>\n",
              "      <td>,</td>\n",
              "      <td>CD</td>\n",
              "      <td>IN</td>\n",
              "      <td>MD</td>\n",
              "      <td>NNS</td>\n",
              "      <td>PRP$</td>\n",
              "      <td>RP</td>\n",
              "      <td>VB</td>\n",
              "      <td>VBP</td>\n",
              "      <td>WP$</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>''</td>\n",
              "      <td>.</td>\n",
              "      <td>DT</td>\n",
              "      <td>JJ</td>\n",
              "      <td>NN</td>\n",
              "      <td>PDT</td>\n",
              "      <td>RB</td>\n",
              "      <td>SYM</td>\n",
              "      <td>VBD</td>\n",
              "      <td>VBZ</td>\n",
              "      <td>WRB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(</td>\n",
              "      <td>:</td>\n",
              "      <td>EX</td>\n",
              "      <td>JJR</td>\n",
              "      <td>NNP</td>\n",
              "      <td>POS</td>\n",
              "      <td>RBR</td>\n",
              "      <td>TO</td>\n",
              "      <td>VBG</td>\n",
              "      <td>WDT</td>\n",
              "      <td>``</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    0  1   2    3    4     5     6    7    8    9   10\n",
              "0   #  )  CC   FW  JJS  NNPS   PRP  RBS   UH  VBN   WP\n",
              "1   $  ,  CD   IN   MD   NNS  PRP$   RP   VB  VBP  WP$\n",
              "2  ''  .  DT   JJ   NN   PDT    RB  SYM  VBD  VBZ  WRB\n",
              "3   (  :  EX  JJR  NNP   POS   RBR   TO  VBG  WDT   ``"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# @title ☜ Print tags\n",
        "\n",
        "all_tags = sorted(list(set(tag for sentence in train for _, tag in sentence)))\n",
        "columns = max(i for i in range(1, len(all_tags) // 2) if len(all_tags) % i == 0)\n",
        "rows = len(all_tags) // columns\n",
        "pd.DataFrame(dict((str(i), all_tags[i * rows:i * rows + rows]) for i in range(columns)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mH4UkmaS0Pg"
      },
      "source": [
        "#POS tagger's API\n",
        "\n",
        "POS tagger should consist of just one function `pos_tag` which takes one argument - list of words (`strings`)\n",
        "\n",
        "***For example:***\n",
        "\n",
        "```\n",
        ">>> tagger.pos_tag([\"I\", \"am\", \"having\", \"fun\", \".\"])\n",
        "\n",
        " [('I', 'PRP'), ('am', 'VBP'), ('having', 'VBG'), ('fun', 'NN'), ('.', '.')]\n",
        "```\n",
        "\n",
        "Please finish the implementation below ☟"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2wOLspuHZhW",
        "outputId": "e27de2b2-73a6-4622-d1eb-bb52bde3fd65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(181099, 44)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "words = []\n",
        "labels = set()\n",
        "for oneline in train:\n",
        "  for token, tag in oneline:\n",
        "    words.append(token)\n",
        "    labels.add(tag)\n",
        "\n",
        "len(words), len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1IR7dEiJJGRl"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "vocab = collections.Counter(words)\n",
        "assert len(vocab) == len(set(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_loD2aY4JF4M",
        "outputId": "1fc9d94d-4261-4033-899b-adfffbb0c718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['UKN', ',', 'the', '.', 'of']\n"
          ]
        }
      ],
      "source": [
        "min_freq = 2\n",
        "list_tokens = [token for token, freq in vocab.most_common() if freq > min_freq]\n",
        "list_tokens = ['UKN'] + list_tokens\n",
        "print(list_tokens[:5])\n",
        "token2idx = {token:idx for idx, token in enumerate(list_tokens)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "A8FNab6aMWuV"
      },
      "outputs": [],
      "source": [
        "label2idx = {label:idx for idx, label in enumerate(list(labels))}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YQN778AHKhvC"
      },
      "outputs": [],
      "source": [
        "token2idx.get('UNK')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVfThoHXJbTK",
        "outputId": "a3947273-95ff-4db7-d105-d319e618f0b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "token2idx['UKN']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl_CzOizLzRt",
        "outputId": "496bff18-17c0-4a1a-d96e-018e091b833d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7561, 7561)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_idx = []\n",
        "label_idx = []\n",
        "for oneline in train:\n",
        "  one_train = [token2idx.get(token, 0) for token, tag in oneline]\n",
        "  one_label = [label2idx.get(tag, 0) for token, tag in oneline]\n",
        "  assert len(one_train) == len(one_label)\n",
        "  train_idx.append(torch.from_numpy(np.array(one_train)))\n",
        "  label_idx.append(torch.from_numpy(np.array(one_label)))\n",
        "assert len(train_idx) == len(label_idx)\n",
        "len(train_idx), len(label_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2nGnkUsHMm5X"
      },
      "outputs": [],
      "source": [
        "# train_idx[:5], label_idx[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Ddb5-PNwLwp7"
      },
      "outputs": [],
      "source": [
        "class PosTagger(nn.Module):\n",
        "  def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "    super(PosTagger, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.embed = nn.Embedding(vocab_size, embedding_dim)\n",
        "    self.lstm = nn.LSTM(embedding_dim, hidden_dim) # dropout = 0.2\n",
        "    self.lin = nn.Linear(hidden_dim, tagset_size)\n",
        "    self.hidden = self.init_hidden()\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return (torch.zeros(1,1,self.hidden_dim), torch.zeros(1,1,self.hidden_dim))\n",
        "\n",
        "  def forward(self, sentence):\n",
        "    embed_out = self.embed(sentence)\n",
        "    lstm_out, self.hidden = self.lstm(embed_out.view(len(sentence),1,-1) , self.hidden)\n",
        "    lin_out = self.lin(lstm_out.view(len(sentence),-1))\n",
        "    output = nn.functional.log_softmax(lin_out, dim =1)\n",
        "    return output \n",
        "\n",
        "  def pos_tag(self, sentence):\n",
        "    pass \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
        "        ''' Initialize the layers of this model.'''\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # embedding layer that turns words into a vector of a specified size\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        # the LSTM takes embedded word vectors (of a specified size) as inputs \n",
        "        # and outputs hidden states of size hidden_dim\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, dropout = 0.2)\n",
        "\n",
        "        # the linear layer that maps the hidden state output dimension \n",
        "        # to the number of tags we want as output, tagset_size (in this case this is 3 tags)\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, tagset_size)\n",
        "        \n",
        "        # initialize the hidden state (see code below)\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "        \n",
        "    def init_hidden(self):\n",
        "        ''' At the start of training, we need to initialize a hidden state;\n",
        "           there will be none because the hidden state is formed based on perviously seen data.\n",
        "           So, this function defines a hidden state with all zeroes and of a specified size.'''\n",
        "        # The axes dimensions are (n_layers, batch_size, hidden_dim)\n",
        "        return (torch.zeros(1, 1, self.hidden_dim),\n",
        "                torch.zeros(1, 1, self.hidden_dim))\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        ''' Define the feedforward behavior of the model.'''\n",
        "        # create embedded word vectors for each word in a sentence\n",
        "\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "\n",
        "        # get the output and hidden state by passing the lstm over our word embeddings\n",
        "        # the lstm takes in our embeddings and hiddent state\n",
        "        lstm_out, self.hidden = self.lstm(embeds.view(len(sentence), 1, -1), self.hidden)\n",
        "\n",
        "        # get the scores for the most likely tag for a word\n",
        "        tag_outputs = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "\n",
        "        tag_scores = F.log_softmax(tag_outputs, dim=1)\n",
        "\n",
        "        return tag_outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8d0bcllLpQC",
        "outputId": "e28b1793-a487-446b-a149-70ec196b4b75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "78 40 6162 44\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(PosTagger(\n",
              "   (embed): Embedding(6162, 78)\n",
              "   (lstm): LSTM(78, 40)\n",
              "   (lin): Linear(in_features=40, out_features=44, bias=True)\n",
              " ),\n",
              " LSTMTagger(\n",
              "   (word_embeddings): Embedding(6162, 78)\n",
              "   (lstm): LSTM(78, 40, dropout=0.2)\n",
              "   (hidden2tag): Linear(in_features=40, out_features=44, bias=True)\n",
              " ))"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "vocab_size = len(token2idx)\n",
        "tagset_size = len(label2idx)\n",
        "embedding_dim = int(vocab_size**0.5)\n",
        "hidden_dim = 40\n",
        "print(embedding_dim, hidden_dim, vocab_size, tagset_size)\n",
        "\n",
        "model = PosTagger(embedding_dim, hidden_dim, vocab_size, tagset_size)\n",
        "model\n",
        "\n",
        "model2 = LSTMTagger(embedding_dim, hidden_dim, vocab_size, tagset_size)\n",
        "model, model2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "SwMnz84fRXj4"
      },
      "outputs": [],
      "source": [
        "# CLASS torch.optim.AdamW(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False, *, maximize=False)\n",
        "\n",
        "import torch.optim as optim \n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.01, weight_decay=0.01)\n",
        "loss_func = torch.nn.NLLLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "VP4yZUjET19y"
      },
      "outputs": [],
      "source": [
        "# train_idx, label_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBDdCtLkT-Qi",
        "outputId": "0dafad92-13cf-440a-f8c3-bb3056940c02"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7561, 7561)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_idx), len(label_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "3wXQ8COWOdLX",
        "outputId": "6e639eab-08cc-4c8d-b08c-31b43b736cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch : 1, \t loss: 28734.360738277435\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/7t/1rvlspxd0fg79d2yv_0x488mz873fg/T/ipykernel_73485/2728123295.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'epoch : {epoch}, \\t loss: {epoch_loss}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "num_epoch = 10\n",
        "for epoch in range(1, num_epoch + 1):\n",
        "  epoch_loss = 0\n",
        "  for sent, label in zip(train_idx, label_idx):\n",
        "    model.hidden = model.init_hidden()\n",
        "    model.zero_grad()\n",
        "    pred = model(sent)\n",
        "    loss = loss_func(pred, label)\n",
        "    epoch_loss += loss.item()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f'epoch : {epoch}, \\t loss: {epoch_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zOMyuPgWJa6Y"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/7t/1rvlspxd0fg79d2yv_0x488mz873fg/T/ipykernel_73485/3050804757.py\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mtag_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/var/folders/7t/1rvlspxd0fg79d2yv_0x488mz873fg/T/ipykernel_73485/1507368001.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# get the output and hidden state by passing the lstm over our word embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# the lstm takes in our embeddings and hiddent state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;31m# get the scores for the most likely tag for a word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    762\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    763\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# normally these epochs take a lot longer \n",
        "# but with our toy data (only 3 sentences), we can do many epochs in a short time\n",
        "n_epochs = 50\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    \n",
        "    epoch_loss = 0.0\n",
        "    \n",
        "    for sentence_in, targets in zip(train_idx, label_idx):\n",
        "        \n",
        "        model2.zero_grad()\n",
        "\n",
        "        model2.hidden = model.init_hidden()\n",
        "\n",
        "        tag_scores = model2(sentence_in)\n",
        "\n",
        "        loss = loss_func(tag_scores, targets)\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "    if(epoch%20 == 19):\n",
        "        print(\"Epoch: %d, loss: %1.5f\" % (epoch+1, epoch_loss/len(training_data)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "id": "V6g_66amCd37"
      },
      "outputs": [],
      "source": [
        "# POS tagger interface, please change anything except the interface\n",
        "class PosTagger:\n",
        "\n",
        "  def pos_tag(self, sentence: List[str]) -> TaggedSentence:\n",
        "    return [(word, \"NN\") for word in sentence]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_jH8kpMT4GS"
      },
      "source": [
        "#Evaluation\n",
        "\n",
        "For evaluation we use two metrics:\n",
        " \n",
        "1.   **Token accuracy** - percent of correctly predicted labels \n",
        "2.   **Sentence accuracy** - percent of sentences where all labels were correct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "54xuwc9lFl-P"
      },
      "outputs": [],
      "source": [
        "# @title ☜ def evaluate(...)\n",
        "# Model evaluation code\n",
        "\n",
        "def evaluate(pos_tagger, dataset: List[TaggedSentence]):\n",
        "  \"\"\"Run a model with a given dataset and return the evaluation metrics.\n",
        "\n",
        "  @param pos_tagger: A POS tagger implementation\n",
        "  @param dataset: A dataset to use for evaluation\n",
        "  @return: Number of correctly predicted tokens, total number of tokens, token\n",
        "    accuracy, sentence accuracy.\n",
        "  \"\"\"\n",
        "  correct_tokens, correct_sentences, total = 0, 0, 0\n",
        "\n",
        "  for expected in dataset:\n",
        "    actual = pos_tagger.pos_tag([w for w, _ in expected])\n",
        "\n",
        "    correct_sentence = True\n",
        "\n",
        "    if len(actual) != len(expected):\n",
        "      raise Exception(f\"Size mismatch: {len(actual)} != {len(expected)}\")\n",
        "\n",
        "    for (_, guess), (_, golden) in zip(actual, expected):\n",
        "      if guess == golden:\n",
        "        correct_tokens += 1\n",
        "      else:\n",
        "        correct_sentence = False\n",
        "      total += 1\n",
        "\n",
        "    if correct_sentence:\n",
        "      correct_sentences += 1\n",
        "  \n",
        "  return pd.DataFrame({\n",
        "          \"Total\": [total], \n",
        "          \"Correct\": [correct_tokens],\n",
        "          \"Token Accuracy\": [correct_tokens / total,], \n",
        "          \"Sentence Accuracy\": [correct_sentences / len(dataset)]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "wiYe1WVxFcxr",
        "outputId": "4f9cda76-2371-48e2-c5cb-072353984435"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-79c6b5da-22a3-4852-86d3-db1677cd1b36\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>Correct</th>\n",
              "      <th>Token Accuracy</th>\n",
              "      <th>Sentence Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>78005</td>\n",
              "      <td>11089</td>\n",
              "      <td>0.142158</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-79c6b5da-22a3-4852-86d3-db1677cd1b36')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-79c6b5da-22a3-4852-86d3-db1677cd1b36 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-79c6b5da-22a3-4852-86d3-db1677cd1b36');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Total  Correct  Token Accuracy  Sentence Accuracy\n",
              "0  78005    11089        0.142158                0.0"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the naive implementation\n",
        "\n",
        "evaluate(PosTagger(), test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv2Uc_huW3rW"
      },
      "source": [
        "#NLTK Baseline\n",
        "\n",
        "NLTK implementation is using a simple perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "rMKvrT4HEKAi",
        "outputId": "48ef7226-ef3c-489a-f50c-2e108a57fd60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4354d703-d786-4316-a25e-a9a74392cc85\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Total</th>\n",
              "      <th>Correct</th>\n",
              "      <th>Token Accuracy</th>\n",
              "      <th>Sentence Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>78005</td>\n",
              "      <td>74700</td>\n",
              "      <td>0.957631</td>\n",
              "      <td>0.422092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4354d703-d786-4316-a25e-a9a74392cc85')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4354d703-d786-4316-a25e-a9a74392cc85 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4354d703-d786-4316-a25e-a9a74392cc85');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Total  Correct  Token Accuracy  Sentence Accuracy\n",
              "0  78005    74700        0.957631           0.422092"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create and evaluate an existing implementation from NLTK\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# run evaluation\n",
        "evaluate(nltk, test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTk1tuc5XIuE",
        "outputId": "d8a8af4d-c55a-440a-94f1-46edbc107638"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 66.0/66.0MB downloaded\n"
          ]
        }
      ],
      "source": [
        "#@title \n",
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "\n",
        "model_gigaword = api.load(\"glove-wiki-gigaword-50\")\n",
        "\n",
        "def to_embeddings(word):\n",
        "  if word in model_gigaword:\n",
        "    return model_gigaword[word]\n",
        "  return np.zeros(model_gigaword.vector_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgSlyk7JGtr_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "[June 1, 22] Grammarly ML Interview v2.1.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "a0946a56eb8d26105b658b3aefe6da1b8fe9fbca1fbf89ea10ac63287a569df2"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
